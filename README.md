<p align="left">
        ä¸­æ–‡</a>&nbsp ï½œ &nbsp<a href="README_EN.md">English</a>
</p>
<br>

<div align="center">
<h1>
  TELEVAL
</h1>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/datasets/Tele-AI/TELEVAL" target="_blank">HuggingFace Dataset</a>ï¸ â€¢ 
ğŸ¤– <a href="https://modelscope.cn/datasets/TeleAI/TELEVAL/files" target="_blank">ModelScope</a> â€¢ 
ğŸ“ƒ <a href="https://arxiv.org/abs/2507.18061" target="_blank">Technical Report</a>
</p>

## æ›´æ–°
- [Update Jul. 25, 2025] ğŸ”¥ æŠ€æœ¯æŠ¥å‘Šå·²æ›´æ–°
- [Update Jun. 5, 2025] æµ‹è¯„ä»£ç ä¸æ•°æ®å‡å·²å¼€æ”¾

## ç®€ä»‹

**TELEVAL** æ˜¯ä¸€ä¸ªé¢å‘è¯­éŸ³å¯¹è¯å¤§æ¨¡å‹ï¼ˆSpoken-Language Models, SLMsï¼‰çš„è¯„æµ‹åŸºå‡†ï¼Œå°†æ¨¡å‹çš„è¯­éŸ³äº¤äº’èƒ½åŠ›æ‹†è§£ä¸ºä¸‰ä¸ªå±‚æ¬¡ï¼š
- **æ„ŸçŸ¥é²æ£’æ€§ï¼ˆPerceptual Robustnessï¼‰**ï¼šå‡†ç¡®æ¥æ”¶ç”¨æˆ·çš„å£°éŸ³ä¿¡å·ï¼›
- **æ˜¾ç¤ºè¯­ä¹‰æ¨æ–­ï¼ˆExplicit Semantic Reasoningï¼‰**ï¼šæ­£ç¡®ç†è§£ç”¨æˆ·æ„å›¾ï¼Œå¹¶ç”Ÿæˆè¯­ä¹‰æ­£ç¡®ã€äº‹å®å¯é çš„å›åº”ï¼›
- **ç¤¾äº¤-è¯­ç”¨ä¸€è‡´æ€§ï¼ˆSocial-Pragmatic Alignmentï¼‰**ï¼šåœ¨å¯¹è¯ä¸­è¡¨ç°å‡ºç¬¦åˆäººç±»äº¤äº’ä¹ æƒ¯çš„è¡Œä¸ºï¼Œå¹¶æ ¹æ®éšå«äº’åŠ¨çº¿ç´¢è°ƒæ•´å›åº”ç­–ç•¥ã€‚

TELEVALä¸ä»…è¡¡é‡æ¨¡å‹æ˜¯å¦æ­£ç¡®å®Œæˆç”¨æˆ·æ„å›¾ï¼ˆReliable Content Fulfillmentï¼‰ä¸ç”Ÿæˆè´¨é‡ï¼Œæ›´å¼ºè°ƒæ¨¡å‹èƒ½å¦ç”Ÿæˆå£è¯­åŒ–ã€éæ¨¡æ¿åŒ–çš„å›åº”ï¼Œå¹¶èƒ½å¤Ÿéšå¼åˆ©ç”¨å‰¯è¯­è¨€ä¿¡æ¯ï¼ˆå¦‚æƒ…ç»ªã€å¹´é¾„çº¿ç´¢ã€éè¯­è¨€ä¿¡å·ï¼‰æ¥æ”¯æ’‘äº¤äº’å†³ç­–ï¼ˆInteractional Appropriatenessï¼‰ã€‚ç›¸æ¯”åœ¨ç‰¹å®š system prompt ä¸‹å¯¹å£°å­¦ä¿¡æ¯è¿›è¡Œæ˜¾å¼åˆ†ç±»æˆ–æ ‡ç­¾é¢„æµ‹çš„è¯„æµ‹ï¼ŒTELEVALç›´æ¥è¯„ä¼°æ¨¡å‹åœ¨å¯¹è¯å›åº”ä¸­ï¼Œæ˜¯å¦éšå¼åœ°æ„ŸçŸ¥å¹¶åˆç†åœ°åˆ©ç”¨äº†è¿™äº›å‰¯è¯­è¨€ä¿¡æ¯ã€‚

- **å¤šç»´å®ç”¨æ€§è¯„ä¼° ğŸ§ **ï¼šè¦†ç›–12å¤§ä»»åŠ¡34ä¸ªæ•°æ®é›†ï¼ŒåŒ…å«åŸºç¡€çŸ¥è¯†ã€æ–¹è¨€ç†è§£ä¸å›åº”ã€åŸºäºå‰¯è¯­è¨€ä¿¡æ¯çš„å›åº”ç­‰å¤šä¸ªä»»åŠ¡ä¸æµ‹è¯„èƒ½åŠ›ï¼Œæ•°æ®æŒç»­æ‰©å……ä¸­ã€‚
- **çœŸå®äº¤äº’æµ‹è¯• ğŸ§**ï¼šç»“åˆå®é™…äº¤äº’éœ€æ±‚ï¼ˆå¦‚çŸ¥è¯†é—®ç­”ã€æ‹Ÿäººé™ªä¼´ç­‰ï¼‰ï¼Œé¿å…äººå·¥åŒ–æˆ–ä¿¡æ¯æ³„éœ²å¼æŒ‡ä»¤å¦‚â€œæˆ‘æ˜¯ä¸ªå°å­©å­ï¼Œæˆ‘åº”è¯¥...â€ã€â€œæˆ‘ç°åœ¨æ˜¯ä»€ä¹ˆå¿ƒæƒ…ï¼Ÿâ€ ï¼Œå…¨é¢è€ƒå¯Ÿæ¨¡å‹å¯¹ç”¨æˆ·è¯­éŸ³çš„è‡ªç„¶å¯¹è¯èƒ½åŠ›ã€‚
- **å¤šè¯­ç§ä¸å¤šæ–¹è¨€æ•°æ®æ”¯æŒ ğŸŒ**ï¼šè¯„æµ‹æ•°æ®ä»¥ä¸­æ–‡æ™®é€šè¯ä¸ºä¸»ï¼ŒåŒæ—¶æ¶µç›–è‹±æ–‡é—®ç­”ä¸å¤šç§ä¸­æ–‡æ–¹è¨€ï¼ˆå¦‚ç²¤è¯­ã€æ²³å—è¯ã€ä¸œåŒ—è¯ã€ä¸Šæµ·è¯ã€å››å·è¯ç­‰ï¼‰ã€‚
- **æ¨¡å—åŒ–è¯„æµ‹æ¡†æ¶ ğŸ”§**ï¼šå®Œæ•´çš„æ¨¡å‹æ¨ç†ä¸ç»“æœè¯„ä¼°æ¡†æ¶ï¼Œæ¨ç†ä¸è¯„ä¼°æµç¨‹è§£è€¦ï¼Œä¾¿äºè‡ªå®šä¹‰æ¨¡å‹ã€ä»»åŠ¡ä¸æ•°æ®é›†ã€‚

## æ”¯æŒçš„æ¨¡å‹ä¸ç»¼åˆå¾—åˆ†
| Rank | Model | Average Score (%)  |
|:--:|:-----:|:-------:|
| ğŸ¥‡ | [Qwen3-Omni](https://github.com/QwenLM/Qwen3-Omni) | 53.46 |
| ğŸ¥ˆ | [StepAudio2-mini](https://github.com/stepfun-ai/Step-Audio2) | 46.64 |
| ğŸ¥‰ | [Mimo-Audio-Instruct](https://github.com/XiaomiMiMo/MiMo-Audio) | 46.10 |
| #4 | GPT4o-Audio (2024-12-17 preview) | 45.46 |
| #5 | [Qwen2.5-Omni](https://github.com/QwenLM/Qwen2.5-Omni) | 42.51 |
| #6 | [Kimi-Audio](https://github.com/MoonshotAI/Kimi-Audio) | 38.82 |
| #7 | [MiniCPM-o-2.6](https://github.com/OpenBMB/MiniCPM-o) | 37.40 |
| #8 | [Baichuan-Omni-1.5](https://github.com/baichuan-inc/Baichuan-Omni-1.5) | 36.90 |
| #9 | [Freeze-Omni](https://github.com/VITA-MLLM/Freeze-Omni) | 33.19 |
| #10 | [GLM-4-Voice](https://github.com/THUDM/GLM-4-Voice) | 31.87 |
| #11 | [LLaMA-Omni2](https://github.com/ictnlp/LLaMA-Omni2) | 24.67 |
| #12 | [SpeechGPT-2.0-preview](https://github.com/OpenMOSS/SpeechGPT-2.0-preview) | 14.49 |

## ç¯å¢ƒå‡†å¤‡
```bash
python -m venv televal-env
source televal-env/bin/activate

# evaluation only
pip install -r requirements_eval.txt

# Install dependencies for inference & evaluation
pip install -r requirements_all.txt
```

åœ¨```requirements_all.txt```ä¸­æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç»¼åˆçš„ç¯å¢ƒï¼Œæ»¡è¶³å„ä¸ªæ¨¡å‹çš„ç‰ˆæœ¬ä¾èµ–ã€‚ä½†æ˜¯ï¼Œä¸€äº›æ¨¡å‹å¦‚```qwen2.5-omni```å’Œ```kimi-audio```è¦æ±‚çš„```transformers```ç‰ˆæœ¬è¾ƒé«˜ï¼Œå› æ­¤åœ¨æ‰§è¡Œè¿™äº›æ¨¡å‹æ¨ç†æ—¶ï¼Œå»ºè®®æŒ‰ç…§requirements_all.txté‡Œçš„æç¤ºå•ç‹¬å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„transformers

## è¿è¡Œç¤ºä¾‹

### Stage 0: æ•°æ®é›†å‡†å¤‡ (å¯é€‰)
æ¡†æ¶æ”¯æŒä»huggingfaceæˆ–æœ¬åœ°è¯»å–parquetï¼Œä»¥åŠè¯»å–æœ¬åœ°jsonlæ–‡ä»¶ä¸¤ç§æ–¹æ³•ã€‚ä½†ç”±äºç½‘é€Ÿçš„å½±å“ï¼Œä»¥åŠéƒ¨åˆ†æ•°æ®é›†è¾ƒå¤§ï¼Œå¼ºçƒˆå»ºè®®å…ˆä»huggingfaceæˆ–modelscopeä¸‹è½½parquetæ•°æ®é›†ï¼Œæ–¹ä¾¿åå¤è°ƒç”¨ã€‚

åœ¨ ```parquet2jsonl.py``` å·¥å…·ä¸­æˆ‘ä»¬æä¾›äº†å¤šç§ç»„åˆæ–¹å¼ï¼Œå¯è‡ªåŠ¨æ‰§è¡Œæ•°æ®é›†çš„ä¸‹è½½ä»¥åŠå¤„ç†ï¼Œå°†æ•°æ®é›†è½¬ä¸ºjsonl + wavæ ¼å¼æ–¹ä¾¿è°ƒç”¨
```bash
# set $save_root_dir and choose a usage mode, then running:
python tools/parquet2jsonl.py
```

å¦‚éœ€ä½¿ç”¨è‡ªæœ‰æ•°æ®é›†ï¼Œå¯å‚è€ƒ[è‡ªå®šä¹‰dataset](assets/custom.md#è‡ªå®šä¹‰dataset)ä¸­çš„æ–¹å¼æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†è¿›è¡Œæµ‹è¯•ã€‚

### Stage 1: æ¨¡å‹æ¨ç† (å¯é€‰)
ä¸‹è½½éœ€è¦æ¨ç†çš„æ¨¡å‹ï¼Œå¹¶é…ç½®```registry/model/offline.yaml```ä¸­ç›¸åº”æ¨¡å‹çš„è·¯å¾„ã€‚

ä»»åŠ¡è¿è¡Œä¾èµ–äº ```registry/infer_task``` ä¸­çš„è®¾ç½®ï¼Œå¦‚æœç›¸åº”```*.yaml```é…ç½®æ–‡ä»¶å·²ä¿®æ”¹å®Œæˆï¼Œå¿«é€Ÿè¿è¡Œå¯æ‰§è¡Œä¾‹å¦‚
```bash
export PYTHONPATH=$PWD:$PYTHONPATH
python main.py --mode "infer" --task "aqa-llamaqa-zh"
```

ï¼ˆ**å¼ºçƒˆå»ºè®®**ï¼‰ä¹Ÿå¯ä»¥ä½¿ç”¨```run.sh```è„šæœ¬ï¼Œæ‰§è¡Œå¤šä»»åŠ¡ã€å¤šæ¨¡å‹è‡ªåŠ¨æ¨ç†ã€‚ä¿®æ”¹```run.sh```ä¸­çš„å‚æ•°å¹¶æ‰§è¡Œ
```bash
bash run.sh  # stage=1
```

### Stage 2: æ‰“åˆ†
å·²æœ‰æ¨ç†ç»“æœï¼Œå¯ä»¥ä½¿ç”¨```run.sh```è„šæœ¬è·å¾—åœ¨å½“å‰eval_taskä¸Šçš„å¾—åˆ†ã€‚

* æ¡†æ¶ä¹Ÿæ”¯æŒè‡ªæœ‰ç»“æœçš„è¯„æµ‹ï¼ˆä¸æ‰§è¡ŒStage 1ï¼‰ï¼Œéœ€ç¡®ä¿å·²æœ‰çš„æ¨¡å‹æ¨ç†ç»“æœä¿å­˜åœ¨ ```${save_dir}/prediction/${model}/${infer_task}.jsonl``` ï¼Œjsonlæ–‡ä»¶æ¯ä¸€è¡Œçš„jsonéœ€è¦è‡³å°‘æœ‰```key, pred, ref```å­—æ®µï¼ˆä¹Ÿå¯è‡ªè¡ŒæŒ‡å®šä¿®æ”¹ï¼‰ï¼Œä¹‹ååŒæ ·æ‰§è¡Œæ¨ç†è„šæœ¬å³å¯ã€‚

### ä¿å­˜ç›®å½•ç»“æ„
æ¨¡å‹æ¨ç†ã€æµ‹è¯„ç»“æœè‡ªåŠ¨ä¿å­˜å¦‚ä¸‹
```text
- $save_dir
    â”œâ”€â”€ prediction
    â”‚   â””â”€â”€ $model
    â”‚       â””â”€â”€ ${dataset}.jsonl
    â”œâ”€â”€ result
    â”‚   â””â”€â”€ $model
    â”‚       â””â”€â”€ ${dataset}_${eval_task}.jsonl
    â”œâ”€â”€ summary
    â”‚   â””â”€â”€ $model
    â”‚       â””â”€â”€ ${dataset}_${eval_task}.jsonl
    â””â”€â”€ results.csv
```

## æ”¯æŒçš„ä»»åŠ¡
å½“å‰æ”¯æŒ34ä¸ªä¸»æ•°æ®é›†ï¼ˆ98ä¸ªå­æ•°æ®é›†ï¼‰ï¼Œæ”¯æŒçš„æ•°æ®é›†ã€ä»»åŠ¡è¯¦è§[assets/task.md](assets/task.md)

## æ•°æ®é›†ä¿¡æ¯
æ•°æ®é›†ä¿¡æ¯ä¸å¯¹åº”çš„æµ‹è¯„èƒ½åŠ›è§ [assets/dataset.md](assets/dataset.md#Dataset_Information)

## å…·ä½“ç»“æœ
ä¸»è¦çš„ç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤º
| **Model**                 | **Basic Knowledge** (%) | **Dialect Comprehension** (%) | **Safety&Morality** (%) | **Humanlike Chitchat** (%) | **Livelihood Policy** (%) | **Multiturn Dialogue** (%) | **Dialect-Aware Response** (%) | **Empathetic Response** (%) | **Age-Aware Response** (%) | **NSV-Aware Response** (%) | **Scene** (%) | **Acoustic Robustness** (%) | **Speech-Text Consistency** (%) | **Response Quality (Speech)** (â¬†) | **Empathetic Response (Speech)** (%) |
|---------------------------|---------------------|---------------------------|-----------------------|------------------------|-----------------------|------------------------|----------------------------|-------------------------|------------------------|------------------------|-----------|-------------------------|-----------------------------|-------------------------------|-----------------------------------|
| **GPT4o-Audio (API)**     | 52.93               | 21.15                     | 96.29                 | 34.45                  | 16.39                 | 84.00                  | 9.19                       | 35.28                   | 17.65                  | 2.52                   | 8.01      | 38.79                   | 98.06                       | 3.46                          | 24.09                             |
| **GLM-4-Voice**           | 31.55               | 13.13                     | 92.55                 | 59.50                  | 16.84                 | 80.00                  | 4.57                       | 35.55                   | 27.81                  | 1.89                   | 0.75      | 32.88                   | 94.45                       | 3.38                          | 34.32                             |
| **MiniCPM-o-2.6**         | 36.16               | 16.67                     | 87.60                 | 58.29                  | 19.78                 | 86.67                  | 10.98                      | 44.03                   | 34.56                  | 2.08                   | 8.91      | 36.18                   | 95.74                       | 3.48                          | 27.90                             |
| **Baichuan-Omni-1.5**     | 34.84               | 30.68                     | 95.00                 | 26.26                  | 19.91                 | 78.67                  | 7.38                       | 13.55                   | 12.24                  | 1.80                   | 1.48      | 42.97                   | 91.31                       | 3.40                          | 23.66                             |
| **LLaMA-Omni2**           | 24.89               | 7.79                      | 77.97                 | 20.77                  | 14.27                 | 54.00                  | 4.26                       | 21.12                   | 13.12                  | 1.77                   | 0.56      | 28.24                   | 98.22                       | 3.49                          | 26.21                             |
| **SpeechGPT-2.0-preview** | 9.88                | 4.98                      | 76.41                 | 41.22                  | 10.38                 | 20.00                  | 5.17                       | 22.59                   | 23.63                  | 1.52                   | 0.27      | 10.70                   | 83.34                       | 2.45                          | 27.78                             |
| **Freeze-Omni**           | 33.05               | 16.44                     | 87.57                 | 30.90                  | 16.64                 | 62.67                  | 5.72                       | 20.72                   | 13.68                  | 1.85                   | 9.15      | 30.48                   | 98.14                       | 3.48                          | 38.87                             |
| **Qwen2.5-Omni**          | 34.77               | 40.54                     | 82.93                 | 80.89                  | 17.89                 | 88.67                  | 18.91                      | 44.83                   | 42.51                  | 2.19                   | 18.90     | 42.79                   | 98.83                       | 3.46                          | 51.71                             |
| **Kimi-Audio**            | 37.18               | 25.71                     | 86.67                 | 47.95                  | 13.45                 | 84.87                  | 10.18                      | 53.17                   | 22.77                  | 9.19                   | 22.01     | 45.30                   | 96.73                       | 3.40                          | 46.25                             |
| **StepAudio2-mini**       | 38.96               | 45.45                     | 91.93                 | 29.25                  | 23.18                 | 82.67                  | 40.12                      | 16.43                   | 18.77                  | 1.97                   | 16.42     | 42.79                   | 94.31                       | 3.22                          | 38.60                             |
| **Qwen3-Omni**            | 50.52               | 41.52                     | 90.11                 | 73.45                  | 22.31                 | 92.67                  | 32.82                      | 44.03                   | 26.43                  | 2.52                   | 18.53     | 50.24                   | 97.86                       | 3.48                          | 48.26                             |
| **Mimo-Audio-Instruct**   | 46.11               | 36.57                     | 99.36                 | 29.27                  | 19.89                 | 88.00                  | 23.74                      | 16.43                   | 11.55                  | 1.87                   | 15.04     | 56.97                   | 31.61                       | 1.80                          | 26.69                             |

* å…¶ä¸­Basic Knowledgeã€Dialect Comprehensionã€Dialect-Aware Responseä¸ºå¤šæ•°æ®é›†çš„åŠ æƒå¹³å‡å€¼ï¼ŒAcoustic Robustnessä¸ºæ¯ç§å£°å­¦è®¾ç½®ä¸­æœ€å·®æƒ…å†µçš„å¹³å‡å€¼ã€‚ç”±äºæµ‹è¯•çš„å¼€æºæ¨¡å‹åŸºæœ¬ä¸å…·å¤‡ "æ— æŒ‡ä»¤æ¡ä»¶ä¸‹å›åº”æ–¹è¨€éŸ³é¢‘"çš„èƒ½åŠ›ï¼Œå› æ­¤ä¸åœ¨æ­¤è¡¨ä¸­å±•ç¤ºã€‚
* ä¸åŒç»´åº¦çš„ç»“æœè§ [assets/result.md](assets/result.md#results)ï¼Œæ›´å¤šå®éªŒç»“æœåŠåˆ†æè§ <a href="https://arxiv.org/abs/2507.18061" target="_blank">Technical Report</a>


## è‡ªå®šä¹‰æ•°æ®é›†ä¸æ¨¡å‹
æœ¬æ¡†æ¶æä¾›äº†å®Œæ•´çš„æ¨¡å‹æ¨ç†ã€ç»“æœè¯„ä»·çš„æµç¨‹ï¼Œæ”¯æŒçµæ´»çš„ä»»åŠ¡ã€æ•°æ®é›†ã€æ¨¡å‹å®šä¹‰ï¼Œåªéœ€è¦ä¿®æ”¹```registry```ä¸‹å¯¹åº”é…ç½®æ–‡ä»¶ï¼›å¦‚éœ€æ–°å¢æ¨¡å‹ï¼Œåˆ™è¦ç»§æ‰¿ **```Model```** ç±»ï¼Œå¹¶å®ç° **```generate_once```** ä¸ **```generate_multiturn```** æ–¹æ³•ã€‚è¯¦è§[assets/custom.md](assets/custom.md)


## è‡´è°¢ä¸å£°æ˜
* æœ¬æ¡†æ¶ä¸­çš„éƒ¨åˆ†ä»£ç å¼•ç”¨ã€ä¿®æ”¹è‡ª [UltraEval-Audio](https://github.com/OpenBMB/UltraEval-Audio) å’Œ [OpenCompass](https://github.com/open-compass/opencompass)
* æ•°æ®é›†ä¸­```llamaqa-en, triviaqa-en, webq-en```çš„éŸ³é¢‘æ¥è‡ª[https://huggingface.co/TwinkStart](https://huggingface.co/TwinkStart)ï¼Œæˆ‘ä»¬å¯¹è¿™äº›æ•°æ®é›†è¿›è¡Œäº†äººå·¥ç­›é€‰ï¼Œå»é™¤ä¸é€‚åˆä½œä¸ºé—®ç­”æµ‹è¯•çš„æ•°æ®ï¼Œå¹¶å¯¹ç­”æ¡ˆè¿›è¡Œäº†è®¢æ­£ï¼Œå› æ­¤æ€»æ¡æ•°ä¼šå°‘äºæºæ•°æ®é›†çš„æ¡æ•°ã€‚
* å„SLMçš„æ¨ç†å®ç°åŸºäºç›¸åº”å¼€æºé¡¹ç›®çš„æ¼”ç¤ºè„šæœ¬ï¼Œæˆ‘ä»¬å¯¹å…¶è¿›è¡Œäº†ç»“æ„ä¸Šçš„ä¿®æ”¹ï¼Œä»¥ä¾¿æ— ç¼é›†æˆåˆ°TELEVALæ¡†æ¶ä¸­ã€‚ç„¶è€Œï¼Œä¸ºäº†ç¡®ä¿æ‰€æœ‰æ¨¡å‹éƒ½èƒ½æ‰§è¡Œ *greedy_search* æ¨ç†ï¼Œæˆ‘ä»¬è°ƒæ•´äº†ä¸€äº›æ¨¡å‹çš„ä»£ç ï¼Œä¾‹å¦‚ ```src_freezeomni/audioLLM.py```

## å¼•ç”¨
å¦‚æœTELEVALå¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼ŒæœŸå¾…æ‚¨èƒ½ç»™ä¸€ä¸ªâ­å’Œå¼•ç”¨
```bibtex
@article{li2025televal,
  title={TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios},
  author={Zehan Li and Hongjie Chen and Qing Wang and Yuxin Zhang and Jing Zhou and Hang Lv and Mengjie Du and Yaodong Song and Jie Lian and Jian Kang and Jie Li and Yongxiang Li and Xuelong Li},
  journal={arXiv preprint arXiv:2507.18061},
  year={2025}
}
```