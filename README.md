<p align="left">
        ä¸­æ–‡</a>&nbsp ï½œ &nbsp<a href="README_EN.md">English</a>
</p>
<br>

<div align="center">
<h1>
  TELEVAL
</h1>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/datasets/Tele-AI/TELEVAL" target="_blank">HuggingFace Dataset</a>ï¸ â€¢ 
ğŸ“ƒ <a href="https://arxiv.org/abs/2507.18061" target="_blank">Technical Report</a>
</p>

## æ›´æ–°
- [Update Jul. 25, 2025] ğŸ”¥ æŠ€æœ¯æŠ¥å‘Šå·²æ›´æ–°
- [Update Jun. 5, 2025] æµ‹è¯„ä»£ç ä¸æ•°æ®å‡å·²å¼€æ”¾

## ç®€ä»‹

**TELEVAL** æ˜¯ä¸€ä¸ªä¸ºè¯­éŸ³å¯¹è¯å¤§æ¨¡å‹ï¼ˆSpoken-Language Models, SLMsï¼‰è®¾è®¡çš„åŠ¨æ€è¯„æµ‹åŸºå‡†ï¼Œé’ˆå¯¹ä¸­æ–‡äº¤äº’åœºæ™¯ï¼Œåˆ’åˆ†ä¸ºä¸‰ä¸ªç»´åº¦ï¼šæ˜¾æ€§è¯­ä¹‰ï¼ˆExplicit Semanticsï¼‰ã€éšæ€§è¯­ä¹‰ä¸å‰¯è¯­è¨€ä¿¡æ¯ï¼ˆParalinguistic & Implicit Semanticsï¼‰ã€ç³»ç»Ÿèƒ½åŠ›ï¼ˆSystem Abilitiesï¼‰ã€‚åŒ…å«åŸºç¡€çŸ¥è¯†ã€æ–¹è¨€ç†è§£ä¸å›åº”ã€å‰¯è¯­è¨€ä¿¡æ¯ç†è§£ä¸å›åº”ç­‰å¤šä¸ªä»»åŠ¡ä¸æµ‹è¯„èƒ½åŠ›ã€‚

- **å¤šç»´å®ç”¨æ€§è¯„ä¼° ğŸ§ **ï¼šè¦†ç›–12å¤§ä»»åŠ¡34ä¸ªæ•°æ®é›†ï¼Œæ•°æ®æŒç»­æ‰©å……ä¸­ã€‚
- **çœŸå®äº¤äº’æµ‹è¯• ğŸ§**ï¼šæ¨¡ç»“åˆå®é™…äº¤äº’éœ€æ±‚ï¼ˆå¦‚çŸ¥è¯†é—®ç­”ã€æ‹Ÿäººé™ªä¼´ç­‰ï¼‰ï¼Œæ„é€ è‡ªç„¶ã€çœŸå®çš„å¯¹è¯åœºæ™¯ï¼Œé¿å…ä»»åŠ¡å‹æŒ‡ä»¤å¦‚â€œæˆ‘æ˜¯ä¸ªå°å­©å­ï¼Œæˆ‘åº”è¯¥...â€ã€â€œæˆ‘ç°åœ¨æ˜¯ä»€ä¹ˆå¿ƒæƒ…ï¼Ÿâ€ ï¼Œå…¨é¢è€ƒå¯Ÿæ¨¡å‹å¯¹ç”¨æˆ·è¯­éŸ³çš„è‡ªç„¶å¯¹è¯èƒ½åŠ›ã€‚
- **å¤šè¯­ç§ä¸å¤šæ–¹è¨€æ•°æ®æ”¯æŒ ğŸŒ**ï¼šè¯„æµ‹æ•°æ®ä»¥ä¸­æ–‡æ™®é€šè¯ä¸ºä¸»ï¼ŒåŒæ—¶æ¶µç›–è‹±æ–‡é—®ç­”ä¸å¤šç§ä¸­å›½æ–¹è¨€ï¼ˆå¦‚ç²¤è¯­ã€æ²³å—è¯ã€ä¸œåŒ—è¯ã€ä¸Šæµ·è¯ã€å››å·è¯ç­‰ï¼‰ã€‚
- **æ¨¡å—åŒ–è¯„æµ‹æ¡†æ¶ ğŸ”§**ï¼šå®Œæ•´çš„æ¨¡å‹æ¨ç†ä¸ç»“æœè¯„ä¼°æ¡†æ¶ï¼Œæ¨ç†ä¸è¯„ä¼°æµç¨‹è§£è€¦ï¼Œæ”¯æŒä½¿ç”¨å·²æœ‰æ¨ç†ç»“æœè¿›è¡Œè¯„ä¼°ï¼Œè‡ªå®šä¹‰æ¨¡å‹ã€ä»»åŠ¡ä¸æ•°æ®é›†ã€‚æ”¯æŒSLMå’ŒLLMçš„æ¨ç†ã€è¯„ä¼°ã€‚

## ç¯å¢ƒå‡†å¤‡
```bash
python3.10 -m venv televal-env
source televal-env/bin/activate

# Install dependencies for inference & evaluation
pip install -r requirements_all.txt

# evaluation only
pip install -r requirements_eval.txt
```

åœ¨```requirements_all.txt```ä¸­æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç»¼åˆçš„ç¯å¢ƒï¼Œæ»¡è¶³å„ä¸ªæ¨¡å‹çš„ç‰ˆæœ¬ä¾èµ–ã€‚ä½†æ˜¯```qwen2.5-omni```å’Œ```kimi-audio```è¦æ±‚çš„```transformers```ç‰ˆæœ¬è¾ƒé«˜ï¼Œå› æ­¤åœ¨æ‰§è¡Œè¿™ä¸¤ä¸ªæ¨¡å‹æ¨ç†æ—¶ï¼Œå»ºè®®ä½¿ç”¨
```bash
pip install transformers==4.52.3  # required by qwen2.5-omni
```

## è¿è¡Œç¤ºä¾‹

### Stage 0: æ•°æ®é›†å‡†å¤‡ (å¯é€‰)
æ¡†æ¶æ”¯æŒä»huggingfaceè¯»å–parquetï¼Œä»¥åŠè¯»å–æœ¬åœ°jsonlæ–‡ä»¶ä¸¤ç§æ–¹æ³•ã€‚ä½†ç”±äºç½‘é€Ÿçš„å½±å“ï¼Œä»¥åŠéƒ¨åˆ†æ•°æ®é›†è¾ƒå¤§ï¼Œæˆ‘ä»¬å»ºè®®åœ¨ä½¿ç”¨å‰å…ˆå°†æ•°æ®é›†ä¸‹è½½å¹¶ä¿å­˜ä¸º jsonl + wav çš„å½¢å¼ï¼Œæ–¹ä¾¿åå¤è°ƒç”¨ã€‚æˆ‘ä»¬æä¾›äº†ä¸€ä¸ª ```parquet2jsonl.py``` å·¥å…·å¯è‡ªåŠ¨æ‰§è¡Œæ•°æ®é›†çš„ä¸‹è½½ã€æ ¼å¼è½¬æ¢
```bash
# set $save_root_dir to the local directory for saving data
python tools/parquet2jsonl.py
```

å¦‚éœ€ä½¿ç”¨è‡ªæœ‰æ•°æ®é›†ï¼Œå¯å‚è€ƒ[è‡ªå®šä¹‰dataset](assets/custom.md#è‡ªå®šä¹‰dataset)ä¸­çš„æ–¹å¼æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†è¿›è¡Œæµ‹è¯•ã€‚

### Stage 1: æ¨¡å‹æ¨ç† (å¯é€‰)
ä¸‹è½½éœ€è¦æ¨ç†çš„æ¨¡å‹ï¼Œå¹¶é…ç½®```registry/model/offline.yaml```ä¸­ç›¸åº”æ¨¡å‹çš„è·¯å¾„ã€‚

ä»»åŠ¡è¿è¡Œä¾èµ–äº ```registry/infer_task``` ä¸­çš„è®¾ç½®ï¼Œå¦‚æœç›¸åº”```*.yaml```é…ç½®æ–‡ä»¶å·²ä¿®æ”¹å®Œæˆï¼Œå¿«é€Ÿè¿è¡Œå¯æ‰§è¡Œ
```bash
export PYTHONPATH=$PWD:$PYTHONPATH
python main.py --mode "infer" --task "aqa"
```

æ¡†æ¶æ”¯æŒå…¨å±€å‚æ•°è®¾ç½®ï¼Œä»è€Œé¿å…åå¤è°ƒæ•´é…ç½®æ–‡ä»¶ï¼Œå¯æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤
```bash
export PYTHONPATH=$PWD:$PYTHONPATH
infer_task="aqa-llamaqa-zh" # infer tasks defined in registry/infer_task
save_dir="xxx/res"               # prediction and evaluation result saving root dir
save_pred_audio=False        # if True, will save prediction audio
model="freeze_omni"          # model name defined in registry/model
python main.py --mode "infer" --task $infer_task --save_dir $save_dir --save_pred_audio $save_pred_audio --model $model
```

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ª```run.sh```è„šæœ¬ï¼Œå¯ä»¥æ‰§è¡Œå¤šä»»åŠ¡ã€å¤šæ¨¡å‹è‡ªåŠ¨æ¨ç†ã€‚ä¿®æ”¹```run.sh```ä¸­çš„å‚æ•°å¹¶æ‰§è¡Œ
```bash
bash run.sh
```

### Stage 2: æ‰“åˆ†
å·²æœ‰æ¨ç†ç»“æœï¼Œå¯æ‰§è¡Œå¦‚ä¸‹æ¨ç†è„šæœ¬è·å¾—åœ¨å½“å‰eval_taskä¸Šçš„å¾—åˆ†
```bash
export PYTHONPATH=$PWD:$PYTHONPATH
infer_task="aqa-llamaqa-zh"   # infer tasks defined in registry/infer_task
save_dir="xxx/res"           # prediction and evaluation result saving root dir, sub-dir can be used
save_pred_audio=False         # if True, will save prediction audio
model="freeze_omni"           # model name defined in registry/model
python main.py --mode "eval" --task $infer_task --save_dir $save_dir --model $model
```

åŒæ ·çš„ï¼Œå¯ä»¥ä½¿ç”¨```run.sh```è„šæœ¬ä¸€ç«™å¼å®Œæˆæ‰“åˆ†ã€‚

* æ¡†æ¶ä¹Ÿæ”¯æŒè‡ªæœ‰ç»“æœçš„è¯„æµ‹ï¼ˆä¸æ‰§è¡ŒStage 1ï¼‰ï¼Œéœ€ç¡®ä¿å·²æœ‰çš„æ¨¡å‹æ¨ç†ç»“æœä¿å­˜åœ¨ ```${save_dir}/prediction/${model}/${infer_task}.jsonl``` ï¼Œjsonlæ–‡ä»¶æ¯ä¸€è¡Œçš„jsonéœ€è¦è‡³å°‘æœ‰```key, pred, ref```å­—æ®µï¼ˆä¹Ÿå¯è‡ªè¡ŒæŒ‡å®šä¿®æ”¹ï¼‰ï¼Œä¹‹ååŒæ ·æ‰§è¡Œæ¨ç†è„šæœ¬å³å¯ã€‚

### ä¿å­˜ç›®å½•ç»“æ„
æ¨¡å‹æ¨ç†ã€æµ‹è¯„ç»“æœè‡ªåŠ¨ä¿å­˜å¦‚ä¸‹
```text
- $save_dir
    â”œâ”€â”€ prediction
    â”‚   â””â”€â”€ $model
    â”‚       â””â”€â”€ ${dataset}.jsonl
    â”œâ”€â”€ result
    â”‚   â””â”€â”€ $model
    â”‚       â””â”€â”€ ${dataset}_${eval_task}.jsonl
    â”œâ”€â”€ summary
    â”‚   â””â”€â”€ $model
    â”‚       â””â”€â”€ ${dataset}_${eval_task}.jsonl
    â””â”€â”€ results.csv
```

## æ”¯æŒçš„æ•°æ®é›†å’Œä»»åŠ¡
å½“å‰æ”¯æŒ34ä¸ªä¸»æ•°æ®é›†ï¼ˆ98ä¸ªå­æ•°æ®é›†ï¼‰ï¼Œæ”¯æŒçš„æ•°æ®é›†ã€ä»»åŠ¡è¯¦è§[assets/task.md](assets/task.md)

## æ”¯æŒçš„æ¨¡å‹
| Model          | Link  |
|:-------------:|:-------:|
| glm-4-voice-9b | [GLM-4-Voice](https://github.com/THUDM/GLM-4-Voice) |
| MiniCPMo2_6-audio | [MiniCPM-o-2.6](https://github.com/OpenBMB/MiniCPM-o) |
| baichuan_omni_1d5 | [Baichuan-Omni-1.5](https://github.com/baichuan-inc/Baichuan-Omni-1.5) |
| llama_omni | [LLaMA-Omni](https://github.com/ictnlp/LLaMA-Omni) |
| speechgpt2 | [SpeechGPT-2.0-preview](https://github.com/OpenMOSS/SpeechGPT-2.0-preview) |
| freeze_omni | [Freeze-Omni](https://github.com/VITA-MLLM/Freeze-Omni) |
| qwen2_5_omni | [Qwen2.5-Omni](https://github.com/QwenLM/Qwen2.5-Omni) |
| kimi-audio-7b-instruct | [Kimi-Audio](https://github.com/MoonshotAI/Kimi-Audio) |

## æ•°æ®é›†ä¿¡æ¯
æ•°æ®é›†ä¿¡æ¯ä¸å¯¹åº”çš„æµ‹è¯„èƒ½åŠ›è§ [assets/dataset.md](assets/dataset.md#Dataset_Information)

## å¼€æºæ¨¡å‹ç»“æœ
ä¸»è¦çš„ç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤º
| **Model**                | **Basic Knowledge** (%) | **Dialect Comprehension** (%) | **Value Align** (%) | **Chitchat** (%) | **Dialect P&R** (%) | **Emotion P&R** (%) | **Age P&R** (%) | **NSV P&R** (%) | **Scene** (%) | **Acoustic Robustness** (%) | **CER (Speech)** (%) | **DNSMOS (Speech)** â†‘ | **Emo (Speech)** (%) |
|:------------------------:|:-------------------:|:-------------------------:|:---------------:|:------------:|:---------------:|:---------------:|:-----------:|:-----------:|:---------:|:-----------------------:|:-------:|:----------:|:--------:|
| GLM-4-Voice              | 31.55               | 13.13                     | 92.55           | 59.50        | 4.57            | 35.55           | 27.81       | 1.89        | 2.28      | 32.88                   | 6.58    | 3.46       | 31.66    |
| MiniCPM-o-2.6            | 36.16               | 16.67                     | 87.60           | 58.29        | 10.98           | 44.03           | 34.56       | 2.08        | 20.37     | 36.18                   | 2.58    | 3.52       | 34.26    |
| Baichuan-Omni-1.5        | 34.84               | 30.68                     | 95.00           | 26.26        | 7.38            | 13.55           | 12.24       | 1.80        | 3.37      | 42.97                   | 7.89    | 3.40       | 24.74    |
| LLaMA-Omni               | 14.63               | 0.00                      | 49.16           | 9.21         | 0.27            | 8.32            | 3.63        | 0.77        | 0.19      | 12.27                   | 8.33    | 3.21       | 37.28    |
| SpeechGPT-2.0-preview    | 9.88                | 4.98                      | 76.41           | 41.22        | 5.17            | 22.59           | 23.63       | 1.52        | 0.52      | 10.70                   | 17.27   | 2.46       | 27.48    |
| Freeze-Omni              | 33.05               | 16.44                     | 87.57           | 30.90        | 5.72            | 20.72           | 13.68       | 1.85        | 17.75     | 30.48                   | 4.88    | 3.49       | 41.05    |
| Qwen2.5-Omni             | 34.77               | 40.54                     | 82.93           | 80.89        | 18.91           | 44.83           | 42.51       | 2.19        | 32.70     | 42.79                   | 1.69    | 3.47       | 52.59    |
| Kimi-Audio               | 37.18               | 25.71                     | 86.67           | 47.95        | 10.18           | 53.17           | 22.77       | 9.19        | 37.11     | 45.30                   | 3.84    | 3.38       | 45.48    |
| GPT4o-Audio (2024-12-17 preview) | 52.93               | 21.15                     | 96.29           | 34.45        | 9.19            | 35.28           | 17.65       | 2.52        | 14.93     | 38.79                   | 1.94    | 3.46       | 24.09    |

* å…¶ä¸­Basic Knowledgeã€Dialect Comprehensionã€Dialect P&Rä¸ºå¤šæ•°æ®é›†çš„åŠ æƒå¹³å‡å€¼ï¼ŒAcoustic Robustnessä¸ºæ¯ç§å£°å­¦è®¾ç½®ä¸­æœ€å·®æƒ…å†µçš„å¹³å‡å€¼ã€‚ç”±äºæµ‹è¯•çš„å¼€æºæ¨¡å‹åŸºæœ¬ä¸å…·å¤‡ "æ— æŒ‡ä»¤æ¡ä»¶ä¸‹æ–¹è¨€éŸ³é¢‘ç”Ÿæˆ"ï¼Œå› æ­¤ä¸åœ¨æ­¤è¡¨ä¸­å±•ç¤º
* ä¸åŒç»´åº¦çš„ç»“æœè§ [assets/result.md](assets/result.md#results)ï¼Œæ›´å¤šå®éªŒç»“æœåŠåˆ†æè§ <a href="https://arxiv.org/abs/2507.18061" target="_blank">Technical Report</a>


## è‡ªå®šä¹‰æ•°æ®é›†ä¸æ¨¡å‹
æœ¬æ¡†æ¶æä¾›äº†å®Œæ•´çš„æ¨¡å‹æ¨ç†ã€ç»“æœè¯„ä»·çš„æµç¨‹ï¼Œæ”¯æŒçµæ´»çš„ä»»åŠ¡ã€æ•°æ®é›†ã€æ¨¡å‹å®šä¹‰ï¼Œåªéœ€è¦ä¿®æ”¹```registry```ä¸‹å¯¹åº”é…ç½®æ–‡ä»¶ï¼›å¦‚éœ€æ–°å¢æ¨¡å‹ï¼Œåˆ™è¦ç»§æ‰¿ **```Model```** ç±»ï¼Œå¹¶å®ç° **```generate_once```** ä¸ **```generate_multiturn```** æ–¹æ³•ã€‚è¯¦è§[assets/custom.md](assets/custom.md)


## è‡´è°¢ä¸å£°æ˜
* æœ¬æ¡†æ¶ä¸­çš„éƒ¨åˆ†ä»£ç å¼•ç”¨ã€ä¿®æ”¹è‡ª [UltraEval-Audio](https://github.com/OpenBMB/UltraEval-Audio) å’Œ [OpenCompass](https://github.com/open-compass/opencompass)
* æ•°æ®é›†ä¸­```llamaqa-en, triviaqa-en, webq-en```çš„éŸ³é¢‘æ¥è‡ª[https://huggingface.co/TwinkStart](https://huggingface.co/TwinkStart)ï¼Œæˆ‘ä»¬å¯¹è¿™äº›æ•°æ®é›†è¿›è¡Œäº†äººå·¥ç­›é€‰ï¼Œå»é™¤ä¸é€‚åˆä½œä¸ºé—®ç­”æµ‹è¯•çš„æ•°æ®ï¼Œå¹¶å¯¹ç­”æ¡ˆè¿›è¡Œäº†è®¢æ­£ï¼Œå› æ­¤æ€»æ¡æ•°ä¼šå°‘äºæºæ•°æ®é›†çš„æ¡æ•°ã€‚
* å„SLMçš„æ¨ç†å®ç°åŸºäºç›¸åº”å¼€æºé¡¹ç›®çš„æ¼”ç¤ºè„šæœ¬ï¼Œæˆ‘ä»¬å¯¹å…¶è¿›è¡Œäº†ç»“æ„ä¸Šçš„ä¿®æ”¹ï¼Œä»¥ä¾¿æ— ç¼é›†æˆåˆ°TELEVALæ¡†æ¶ä¸­ã€‚ç„¶è€Œï¼Œä¸ºäº†ç¡®ä¿æ‰€æœ‰æ¨¡å‹éƒ½èƒ½æ‰§è¡Œ *greedy_search* æ¨ç†ï¼Œæˆ‘ä»¬è°ƒæ•´äº†ä¸€äº›æ¨¡å‹çš„ä»£ç ï¼Œä¾‹å¦‚ ```src_freezeomni/audioLLM.py```
